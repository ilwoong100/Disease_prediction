{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"uh3RUF58-fpy"},"source":["# Imports"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"Yl1as_58-eEP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","\n","from imblearn.over_sampling import SMOTE\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import accuracy_score, f1_score"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yN6cetsn-lxQ"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"loWnC1YD-mA4"},"outputs":[],"source":["data = pd.read_csv('train.csv')\n","\n","data = data.dropna(subset=['original'])\n","\n","naive_data= data.notnull().sum()\n","\n","# 성별이 NaN 처리된 데이터를 0 또는 1로 채움\n","# 단, 한 사람의 데이터의 경우 성별을 하나로 통일\n","gender = np.random.choice([0,1])\n","for i in data[data['1'].isnull()].iterrows():\n","    if i[1]['timestamp(hr)'] != 0:\n","        data['1'][i[0]] = gender\n","    else:\n","        data['1'][i[0]] = gender\n","        gender = np.random.choice([0,1])\n","\n","# 나이가 NaN처리된 데이터는 나이의 평균값을 반올림하여 채움\n","data['2'].fillna(value= data['2'].mean().round(),inplace=True)\n","\n","\n","# 환자가 확진을 받는 시점 수 == 환자 수\n","patients= []\n","for idx, i in enumerate(data.iterrows()):\n","    if i[1]['timestamp(hr)'] == 0:\n","        patients.append(idx)\n","\n","# 각 환자별로 빈값들을 Linear interpolate 밑 backfill\n","start =0\n","for  end in patients:\n","    data.iloc[start:end+1,:34] = data.iloc[start:end +1, :34].interpolate()\n","    start = end+1\n","start =0\n","for  end in patients:\n","    data.iloc[start:end+1,:34] = data.iloc[start:end +1, :34].interpolate(method='bfill')\n","    start = end+1\n","\n","# 한 환자의 모든 관측정보에서 단한번도 등장하지 않았던 feature값들은 여전히 NaN\n","# 이 값들은 해당 데이터의 평균으로 imputation\n","random_weight = np.random.uniform(-2,2)\n","data.fillna(data.mean()+ random_weight*data.std(),inplace=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["smote\n","======\n","\n","Before Augmentation\n","\n","0: 63085 , -1: 37555, -2: 26548, -3: 48326 (-3 : 20390, -4: 16274, -5: 11662)\n","\n","After using smote\n","\n","0: 63085 , -1: 60000, -2: 60000, -3: 60390 (-3 : 20390, -4: 20000, -5: 20000)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["number of label values timestamp(day)\n"," 0.0    63085\n","-3.0    48326\n","-1.0    37555\n","-2.0    26548\n","Name: count, dtype: int64\n"]}],"source":["day_column = data['timestamp(day)'].copy()\n","\n","day_column[day_column<-3] = -3\n","value_counts = day_column.value_counts()\n","print('number of label values', value_counts)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["number of label values using smote: timestamp(day)\n"," 0.0    63085\n","-3.0    60390\n","-2.0    60000\n","-1.0    60000\n","Name: count, dtype: int64\n"]}],"source":["X = data.drop(['timestamp(day)'], axis=1).copy()\n","selected = data['timestamp(day)'].copy()\n","X_minority = X\n","Y_minority = selected \n","\n","smote = SMOTE(sampling_strategy={-1: 60000, -2: 60000, -4:20000,-5:20000})  \n","X_smote, y_smote = smote.fit_resample(X_minority, Y_minority)\n","\n","X_smote.insert(34, 'timestamp(day)', y_smote)\n","smote_data = X_smote\n","day_column = smote_data['timestamp(day)']\n","\n","day_column[day_column<-3] = -3\n","value_counts = day_column.value_counts()\n","print('number of label values using smote:', value_counts)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Normalize\n","=====\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["before_norm_smote_data = smote_data.copy()\n","#방법 1 : 평균 0, std 1로 normalize\n","scalar = StandardScaler()\n","features = smote_data.columns[:34]\n","smote_data[features] = scalar.fit_transform(smote_data[features])\n","\n","# 방법 2: MIN_MAX Normalization 방식\n","# for column in smote_data.columns[2:34]:\n","#     min_val = smote_data[column].min()\n","#     max_val = smote_data[column].max()\n","#     scaled = (smote_data[column] - min_val) / (max_val - min_val)\n","#     smote_data[column] = scaled"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yGSIpZMc-mb8"},"source":["# EDA\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"4kAua9GP-mrt"},"outputs":[{"name":"stdout","output_type":"stream","text":["number of patients:  4156\n","mean value of label (day) w/o smote: -1.5681199220574997 median value of label (day): w/o smote -1.0\n","mean value of label (day) w smote: -1.4833966526337405 median value of label (day): w smote -1.0\n","          mean         std\n","0     0.586282    0.489377\n","1    65.454468   13.948486\n","2    65.548880   14.630242\n","3   116.696837   28.057438\n","4    97.812259   28.945160\n","5    20.709014    4.972412\n","6    36.967204    8.126593\n","7     0.028184    0.088402\n","8     0.252962    1.011866\n","9   103.336904  110.919508\n","10    5.486900   14.979593\n","11    7.251929   15.749853\n","12    0.063303    0.388214\n","13    0.776463    2.574577\n","14   28.715326    5.761088\n","15    9.614676    1.886887\n","16    0.098206    0.192909\n","17    1.005821    1.856183\n","18    0.623952    0.652399\n","19    8.293801   15.180823\n","20   30.875974    2.628655\n","21   33.357199    2.370280\n","22   92.227721    6.861919\n","23    0.408544    0.488569\n","24    3.819265    4.111012\n","25    9.739905    1.723280\n","26    9.701544    9.419880\n","27   79.982480   17.600148\n","28   56.842856   12.704432\n","29    8.580081    2.912048\n","30  -32.958657   11.123307\n","31    3.106811    0.634518\n","32   16.016585    2.659770\n","33   11.797405   10.658612\n"]}],"source":["# 1) train dataset의 환자수\n","num_patients = len(patients)\n","print('number of patients: ', num_patients)\n","\n","# 2) mean and median value of label timestamp(day)\n","print('mean value of label (day) w/o smote:', data['timestamp(day)'].mean(), \n","    'median value of label (day): w/o smote', data['timestamp(day)'].median())\n","\n","print('mean value of label (day) w smote:', before_norm_smote_data['timestamp(day)'].mean(), \n","    'median value of label (day): w smote', before_norm_smote_data['timestamp(day)'].median())\n","\n","# 3) dataset mean, std and heatmap of feature correlation matrix, and data sparsity\n","mean_std_values = pd.DataFrame(columns=['mean','std'])\n","mean_std_values['mean'] = before_norm_smote_data.iloc[:,:34].mean().values\n","mean_std_values['std'] = before_norm_smote_data.iloc[:,:34].std().values\n","print(mean_std_values)\n","correlation_matrix = before_norm_smote_data[before_norm_smote_data.columns[:34]].corr()\n","plt.figure(figsize=(10,8))\n","sns.heatmap(correlation_matrix, cmap='coolwarm')\n","plt.title('Correlation heatmap')\n","plt.show()\n","\n","print(naive_data)\n","\n","# 4) answer is in report \n","# 5) Calculating eigenvalues, finding appropriate number of dimension to reduce\n","dropped_smote_data = smote_data.drop(columns=['10','16','30','31'])\n","covariance = np.cov(dropped_smote_data.iloc[:,:30].T)\n","eigenvalue = np.linalg.eig(covariance)[0]\n","print(\"number of appropriate eigenvalues: \" ,(eigenvalue>0.83).sum())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pg6SnCu8-nI3"},"source":["# Model Selection\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWJ6mDp3_IxK"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008382 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 7913\n","[LightGBM] [Info] Number of data points in the train set: 175514, number of used features: 34\n","[LightGBM] [Info] Start training from score -34.538776\n","[LightGBM] [Info] Start training from score -34.538776\n","[LightGBM] [Info] Start training from score -1.289749\n","[LightGBM] [Info] Start training from score -1.888764\n","[LightGBM] [Info] Start training from score -1.541912\n","[LightGBM] [Info] Start training from score -1.023236\n"]},{"data":{"text/plain":["0.21690785972856635"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# import lightgbm as lgb\n","# d_train = lgb.Dataset(data.iloc[:,:34], label = data.iloc[:,34]+5)\n","# params={}\n","# params['learning_rate'] = 0.003\n","# params['boosting_type'] = 'gbdt'\n","# params['objective'] = 'multiclass'\n","# params['num_class'] = 6\n","# clf = lgb.train(params, d_train, 100)\n","\n","# train_pred = clf.predict(data.iloc[:,:34]).argmax(axis=1)-5\n","# train_pred[train_pred < -3] = -3\n","\n","# train_label = data.iloc[:,34]\n","# train_label[train_label < -3] = -3\n","# accuracy_score(train_pred, train_label )\n","# f1_score(train_label, train_pred, average='macro')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Zl_ZtSTd_JFA"},"source":["# Model Tuning\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rH-i_pz_JdU"},"outputs":[{"name":"stdout","output_type":"stream","text":["         1     2         3         4         5    6         7         8   \n","0      0.0  88.0  0.567164  0.413636  0.316832  0.2  0.292969  0.087719  \\\n","122    0.0  88.0  0.567164  0.413636  0.316832  0.2  0.292969  0.035088   \n","123    0.0  88.0  0.567164  0.413636  0.316832  0.2  0.292969  0.035088   \n","125    0.0  88.0  0.563433  0.561364  0.383663  0.2  0.285216  0.035088   \n","127    0.0  88.0  0.559701  0.709091  0.450495  0.2  0.290643  0.035088   \n","...    ...   ...       ...       ...       ...  ...       ...       ...   \n","69118  1.0  65.0  0.544776  0.586364  0.450495  0.2  0.295295  0.016412   \n","69120  1.0  65.0  0.496269  0.538636  0.440594  0.2  0.291419  0.016412   \n","69122  1.0  65.0  0.447761  0.490909  0.430693  0.2  0.290643  0.016412   \n","69124  1.0  65.0  0.447761  0.490909  0.430693  0.2  0.289093  0.016412   \n","69126  1.0  65.0  0.447761  0.490909  0.430693  0.2  0.289868  0.016412   \n","\n","              9        10  ...        28   29        30   31        32   \n","0      0.079365  0.256320  ...  0.704684  0.0  0.358986  0.0  0.709102  \\\n","122    0.031746  0.256320  ...  0.928717  0.0  0.448241  0.0  0.639287   \n","123    0.031746  0.256320  ...  0.928717  0.0  0.448241  0.0  0.639287   \n","125    0.031746  0.256320  ...  0.928717  0.0  0.448241  0.0  0.639287   \n","127    0.031746  0.256320  ...  0.928717  0.0  0.448241  0.0  0.639287   \n","...         ...       ...  ...       ...  ...       ...  ...       ...   \n","69118  0.001224  0.000051  ...  0.008392  0.0  0.000000  0.0  0.000000   \n","69120  0.001224  0.000051  ...  0.008392  0.0  0.000000  0.0  0.000000   \n","69122  0.001224  0.000051  ...  0.008392  0.0  0.000000  0.0  0.000000   \n","69124  0.001224  0.000051  ...  0.008392  0.0  0.000000  0.0  0.000000   \n","69126  0.001224  0.000051  ...  0.008392  0.0  0.000000  0.0  0.000000   \n","\n","             33        34  timestamp(day)  timestamp(hr)  original  \n","0      0.784093  0.140909            -3.0         -129.0       1.0  \n","122    0.776096  0.165702             0.0           -7.0       1.0  \n","123    0.776096  0.165702             0.0           -6.0       1.0  \n","125    0.776096  0.165702             0.0           -4.0       1.0  \n","127    0.776096  0.165702             0.0           -2.0       1.0  \n","...         ...       ...             ...            ...       ...  \n","69118  0.000000  0.000783             0.0           -8.0       1.0  \n","69120  0.000000  0.000783             0.0           -6.0       1.0  \n","69122  0.000000  0.000783             0.0           -4.0       1.0  \n","69124  0.000000  0.000783             0.0           -2.0       1.0  \n","69126  0.000000  0.000783             0.0            0.0       1.0  \n","\n","[16277 rows x 37 columns]\n"]},{"data":{"text/plain":["0.23017382859435825"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# test_data = pd.read_csv('test.csv')\n","# test_data = test_data.dropna(subset=['original'])\n","\n","\n","# gender = np.random.choice([0,1])\n","# for i in test_data[test_data['1'].isnull()].iterrows():\n","#     if i[1]['timestamp(hr)'] != 0:\n","#         test_data['1'][i[0]] = gender\n","#     else:\n","#         test_data['1'][i[0]] = gender\n","#         gender = np.random.choice([0,1])\n","\n","# # 나이가 NaN처리된 데이터는 나이의 평균값을 반올림하여 채움\n","# test_data['2'].fillna(value= test_data['2'].mean().round(),inplace=True)\n","\n","# # 환자가 확진을 받는 시점 수 == 환자 수\n","# patients= []\n","# for idx, i in enumerate(test_data.iterrows()):\n","#     if i[1]['timestamp(hr)'] == 0:\n","#         patients.append(idx)\n","\n","# # 각 환자별로 빈값들을 Linear interpolate 밑 backfill\n","# start =0\n","# for  end in patients:\n","#     test_data.iloc[start:end+1,:34] = test_data.iloc[start:end +1, :34].interpolate()\n","#     start = end+1\n","# start =0\n","# for  end in patients:\n","#     test_data.iloc[start:end+1,:34] = test_data.iloc[start:end +1, :34].interpolate(method='bfill')\n","#     start = end+1\n","\n","# test_data.fillna(data.mean(),inplace=True)\n","\n","# for column in test_data.columns[2:34]:\n","#     min_val = test_data[column].min()\n","#     max_val = test_data[column].max()\n","#     scaled = (test_data[column] - min_val) / (max_val - min_val)\n","#     test_data[column] = scaled\n","\n","# y_label = test_data.iloc[:,34]\n","# y_label[y_label < -3 ] = -3\n","# print(test_data)\n","\n","\n","# x_data = test_data.iloc[:,:34]\n","# y_pred = clf.predict(x_data) \n","\n","# y_pred = y_pred.argmax(axis=1)-5\n","\n","# # y_pred = np.array(y_pred)\n","# y_pred[y_pred < -3] = -3 \n","\n","\n","# accuracy_score(y_label, y_pred)\n","# f1_score(y_label, y_pred, average='macro')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y-k5WmJq_NCU"},"source":["# Model Evaluation / Metrics"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
